install.packages("blogdown")
blogdown::intall_hugo()
blogdown::install_hugo()
blogdown::new_site(ttheme = "panr/hugo-theme-terminal")
blogdown::new_site(theme = "panr/hugo-theme-terminal")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::new_site(theme = "nurlansu/hugo-sustain")
blogdown::serve_site()
blogdown::serve_site()
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
womensrole <- read_excel("Downloads/womensrole.xlsx")
View(womensrole)
womensrole$sex<-as.character(womensrole$sex)
WR1<-manova(cbind(disagree, education)~sex, data=womensrole)
summary(WR1)
summary.aov(WR1)
summary(aov(disagree~education, data=womensrole))
obs_F<-7.391
Fs<-replicate(5000,{
new<-womensrole%>%mutate(education=sample(disagree))
SSW<- new%>%group_by(education)%>%summarize(SSW=sum((disagree-mean(disagree))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(disagree))%>%group_by(education)%>%mutate(groupmean=mean(disagree))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/1)/(SSW/36)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
library(dplyr)
library(lmtest)
library(sandwich)
WR2<-womensrole%>%mutate(y=ifelse(sex=="Male",1,0))
WR2$education_c<-WR2$education-mean(WR2$education, na.rm=T)
WR2$agree_c<-WR2$agree-mean(WR2$agree, na.rm=T)
fit<-lm(disagree~education*agree, data=WR2)
summary(fit)
fit_c<-lm(disagree~education_c*agree_c, data=WR2)
summary(fit_c)
#Plotting the Interaction Plot, mean-centered
ggplot(WR2, aes(x=education_c*agree_c, y=disagree))+geom_smooth(method="lm")
#Checking assumptions of linearity and homoskedasticity
resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals, resids))+geom_hline(yintercept=0, color='red')
bptest(disagree~education, data=WR2)
bptest(disagree~agree, data=WR2)
bptest(disagree~education*agree, data=WR2)
#Checking for assumption of normality
ggplot()+geom_histogram(aes(resids), bins=20)
shapiro.test(resids)
#Regression results with Robust Standard Errors
coeftest(fit, vcov=vcovHC(fit))[,1:2]
(sum((WR2$disagree-mean(WR2$disagree))^2)-sum(fit$residuals^2))/sum((WR2$disagree-mean(WR2$disagree))^2)
#Running the same regression model with interaction and the mean-centered version
fit<-lm(disagree~education*agree, data=WR2)
summary(fit)
fit_c<-lm(disagree~education_c*agree_c, data=WR2)
summary(fit_c)
#Creating Bootstrapped Standard Errors
bootstrapSE<-function(x,n=5000){
means<-vector()
for(i in 1:n){
means[i]<-mean(sample(x,replace=T))
}
return(sd(means))
}
samp_distn<-replicate(5000, {
boot_dat<-boot_dat<-WR2[sample(nrow(WR2),replace=TRUE),]
fit<-lm(disagree~education_c*agree_c, data=boot_dat)
coef(fit)
})
#Bootstrapped Standard Errors that resample rows
library(dplyr)
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
#Regression with Normal Standard Errors
coeftest(fit)[,1:2]
#Regression results with Robust Standard Errors
coeftest(fit, vcov=vcovHC(fit))[,1:2]
library(dplyr)
library(MASS)
library(ggplot2)
library(lmtest)
#Making a Categorical Explanatory Variable
WR2$athome<-WR2$education
WR2$athome[c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28)] = "Yes"
WR2$athome[c(11, 12, 13, 14, 15, 16, 17, 18, 19, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42)] = "No"
#Logistic Regression
rit<-glm(y~education+agree, data=WR2, family=binomial(link="logit"))
coeftest(rit)
#Confusion Matrix
probrit<-predict(rit, type="response")
predrit<-ifelse(probrit > 0.5, 1, 0)
logit<-predict(rit)
table(truth=WR2$y, prediction=predrit)%>%addmargins
WR2$logit<-logit
#Computing Accuracy
(6+12)/42
#Computing Sensitivity/Recall (TPR)
12/21
#Computing Specificity (TNR)
6/21
#Computing Precision (PPV)
12/27
#GG-Plot
library(ggplot2)
ggplot(WR2, aes(fill=sex, x=logit))+geom_density(alpha=0.3)
#ROC plot and AUC
library(plotROC)
ROCplot<-ggplot(WR2)+geom_roc(aes(d=y, m=probrit), n.cuts=0)+geom_segment(aes(x=0, xend=1, y=0, yend=1), lty=2)+scale_x_continuous(limits=c(0,1))
ROCplot
calc_auc(ROCplot)
#Repeated Random Sub-Sampling
library(tidyverse); library(lmtest); library(MASS)
WR3<-WR2%>%transmute(education=education, sex=sex, agree=agree, disagree=disagree, education_c=education_c, agree_c=agree_c, athome=athome, logit=logit, y=ifelse(sex=="Male",1,0))
jit<-glm(y~athome+education,data=WR3,family="binomial")
prob<-predict(jit,type="response")
set.seed(1234)
k=5
data1<-WR3[sample(nrow(WR3)),]
folds<-cut(seq(1:nrow(WR3)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$y
hit<-glm(y~athome+education,data=train,family="binomial")
probs<-predict(hit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
devtools::install_github('rstudio/blogdown')
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
devtools::install_github('rstudio/blogdown')
update.packages(ask = FALSE, checkBuilt = TRUE)
devtools::install_github('rstudio/blogdown')
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
knitr::opts_chunk$set(echo = TRUE)
#Creating Better Datasets
dataNPI<-read.csv("Downloads/NPI/dataNPI.csv")
knitr::opts_chunk$set(echo = TRUE)
#Creating Better Datasets
dataNPI<-read.csv("website/content/NPI/dataNPI.csv")
knitr::opts_chunk$set(echo = TRUE)
#Creating Better Datasets
dataNPI<-read.csv("/Users/Nyssa./Desktop/website/content/dataNPI.csv")
dataTMA<-read.csv("/Users/Nyssa./Desktop/website/content/dataTMA.csv")
library(dplyr)
NPI<-dataNPI%>%mutate(gender=recode_factor(gender, '1'="male",
'2'="female", '3'="other", '0'="none")) %>% select(gender, everything())
npi<-NPI[-c(9814, 9905, 9924, 10003, 10146, 10221, 10297, 10414,
10437, 10590, 10929, 11028, 11186, 10163, 10856, 9453, 8161,
8818, 7584, 8121, 8303, 8373, 8403, 8793, 8916, 9001, 9265,
9301, 9421, 9473, 9547, 9725, 9760, 9841, 9929, 9953, 10118,
10137, 10260, 10390, 10443, 10623, 10868, 11067, 11184,
8356, 1272, 9154, 8063, 8269, 9228),]
TMA<-dataTMA%>%mutate(gender=recode_factor(gender, '1'="male",
'2'="female", '3'="other", '0'="none"))
tma<-TMA[-c(3000, 2612, 1240, 4121),]
#Creating Dataset Subsets and Joining
firstnpi<-npi%>%head(500)
firsttma<-tma%>%head(500)
firstnpitma<-full_join(firstnpi, firsttma, by = c("gender","age"))
#Using Dplyr Functions
firstnpitma%>%select(-"elapse")->firstnpitma2
head(firstnpitma2)
firstnpitma2%>%filter(age> 15)%>%arrange(age, score.x, score.y)->firstnpitma3
head(firstnpitma3)
firstnpitma4<-firstnpitma3%>%mutate(age2=ifelse(age<=20,"young",ifelse(20<age & age<40,"middle",ifelse(age>=40,"old",NA))))%>%na.omit()
glimpse(firstnpitma4)
firstnpitma5<- firstnpitma4%>%select(-starts_with("Q"))%>%group_by(gender,age2)
#Generating Summary Statistics
firstnpitma6<-firstnpitma5%>%group_by(gender,age2)%>%summarize(mean_age=mean(age,na.rm=T),mean_score.x=mean(score.x,na.rm=T),mean_score.y=mean(score.y,na.rm=T),sd_score.x=sd(score.x,na.rm=T), sd_score.y=sd(score.y,na.rm=T),median_age=median(age,na.rm=T),median_score.x=median(score.x,na.rm=T), median_score.y=median(score.y,na.rm=T), min_age=min(age,na.rm=T),min_score.x=min(score.x,na.rm=T), min_score.y=min(score.y,na.rm=T), max_age=max(age,na.rm=T), max_score.x=max(score.x,na.rm=T), max_score.y=max(score.y,na.rm=T), n=n(),n_age=n_distinct(age), n_score.x=n_distinct(score.x), n_score.y=n_distinct(score.y),n_age=n_distinct(age),cov_scores=cov(score.x,score.y),var_scores=var(score.x,score.y),cor_scores=cor(score.x,score.y))
glimpse(firstnpitma6)
#Tidying Dataset from Mean Summary Statistics
library(tidyr)
library(tidyverse)
firstnpitma7<-firstnpitma6%>%pivot_wider(names_from="age2", "gender",values_from="mean_score.x")
firstnpitma8<-firstnpitma6%>%pivot_wider(names_from="age2", "gender", values_from="mean_score.y")
glimpse(firstnpitma7)
glimpse(firstnpitma8)
#Creating First GG Plot
ggplot(firstnpitma6, aes(x=firstnpitma6$age2, y=firstnpitma6$mean_score.x))+geom_bar(stat="summary",aes(fill=firstnpitma6$age2))+ geom_errorbar(stat="summary", width=0.4) + labs(x="Age Categories", y="Mean NPI Score")+scale_fill_discrete() +ggtitle("Mean NPI Scores vs. Age Categories") +scale_y_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18))
#Creating Second GG Plot
ggplot(firstnpitma6, aes(x=firstnpitma6$age2, y=firstnpitma6$cor_scores))+ geom_point(stat="summary", fun.data='mean_se', aes(fill=firstnpitma6$age2), color="red", size=4)+ggtitle("Correlation Scores vs. Age Categories")+labs(x="Age Categories", y="Correlation Scores")
#Creating a PCA
library(dplyr)
firstnpitma6%>%ungroup()%>%select(-age2,-gender)->numericnpitma
numericnpitma2<-numericnpitma%>%select_if(is.numeric)%>%scale
npitma_pca<-prcomp(numericnpitma2)
summary(npitma_pca, rotation=T)
npitma_pca$rotation
eigvalnpitma<-npitma_pca$sdev^2
npitmadf<-data.frame(PC1=npitma_pca$x[,1], PC2=npitma_pca$x[,2])
npitmadf2<-data.frame(PC3=npitma_pca$x[,3], PC4=npitma_pca$x[,4])
ggplot(npitmadf,aes(PC1, PC2))+geom_point()
ggplot(npitmadf2,aes(PC3, PC4))+geom_point()
npitma_pca$rotation[3:2,4:3]%>%as.data.frame%>%rownames_to_column%>%
ggplot()+geom_hline(aes(yintercept=0),lty=2)+
geom_vline(aes(xintercept=0),lty=2)+ylab("PC4")+xlab("PC3")+
geom_segment(aes(x=0,y=0,xend=PC3,yend=PC4),arrow=arrow(),col="red")+
geom_label(aes(x=PC3*0.8,y=PC4,label=rowname))
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
womensrole <- read_csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
View(womensrole)
womensrole$sex<-as.character(womensrole$sex)
WR1<-manova(cbind(disagree, education)~sex, data=womensrole)
View(womensrole)
library(readxl)
womensrole <- read_excel("content/womensrole.csv")
View(womensrole)
View(dataNPI)
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
womensrole <- read.csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
womensrole<-read.csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
womensrole<-read.csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
womensrole<-read.csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
womensrole<-read.csv("/Users/Nyssa./Desktop/website/content/womensrole.csv
")
library(readxl)
dataset <- read_excel(NULL)
View(dataset)
library(readxl)
womensrole <- read_excel("content/womensrole.csv")
View(womensrole)
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
womensrole <- read_excel("/Users/Nyssa./Desktop/website/content/womensrole.xls")
View(womensrole)
womensrole$sex<-as.character(womensrole$sex)
WR1<-manova(cbind(disagree, education)~sex, data=womensrole)
summary(WR1)
summary.aov(WR1)
summary(aov(disagree~education, data=womensrole))
obs_F<-7.391
Fs<-replicate(5000,{
new<-womensrole%>%mutate(education=sample(disagree))
SSW<- new%>%group_by(education)%>%summarize(SSW=sum((disagree-mean(disagree))^2))%>%summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(disagree))%>%group_by(education)%>%mutate(groupmean=mean(disagree))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/1)/(SSW/36)
})
hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
library(dplyr)
library(lmtest)
library(sandwich)
WR2<-womensrole%>%mutate(y=ifelse(sex=="Male",1,0))
WR2$education_c<-WR2$education-mean(WR2$education, na.rm=T)
WR2$agree_c<-WR2$agree-mean(WR2$agree, na.rm=T)
fit<-lm(disagree~education*agree, data=WR2)
summary(fit)
fit_c<-lm(disagree~education_c*agree_c, data=WR2)
summary(fit_c)
#Plotting the Interaction Plot, mean-centered
ggplot(WR2, aes(x=education_c*agree_c, y=disagree))+geom_smooth(method="lm")
#Checking assumptions of linearity and homoskedasticity
resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals, resids))+geom_hline(yintercept=0, color='red')
bptest(disagree~education, data=WR2)
bptest(disagree~agree, data=WR2)
bptest(disagree~education*agree, data=WR2)
#Checking for assumption of normality
ggplot()+geom_histogram(aes(resids), bins=20)
shapiro.test(resids)
#Regression results with Robust Standard Errors
coeftest(fit, vcov=vcovHC(fit))[,1:2]
(sum((WR2$disagree-mean(WR2$disagree))^2)-sum(fit$residuals^2))/sum((WR2$disagree-mean(WR2$disagree))^2)
#Running the same regression model with interaction and the mean-centered version
fit<-lm(disagree~education*agree, data=WR2)
summary(fit)
fit_c<-lm(disagree~education_c*agree_c, data=WR2)
summary(fit_c)
#Creating Bootstrapped Standard Errors
bootstrapSE<-function(x,n=5000){
means<-vector()
for(i in 1:n){
means[i]<-mean(sample(x,replace=T))
}
return(sd(means))
}
samp_distn<-replicate(5000, {
boot_dat<-boot_dat<-WR2[sample(nrow(WR2),replace=TRUE),]
fit<-lm(disagree~education_c*agree_c, data=boot_dat)
coef(fit)
})
#Bootstrapped Standard Errors that resample rows
library(dplyr)
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
#Regression with Normal Standard Errors
coeftest(fit)[,1:2]
#Regression results with Robust Standard Errors
coeftest(fit, vcov=vcovHC(fit))[,1:2]
library(dplyr)
library(MASS)
library(ggplot2)
library(lmtest)
#Making a Categorical Explanatory Variable
WR2$athome<-WR2$education
WR2$athome[c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28)] = "Yes"
WR2$athome[c(11, 12, 13, 14, 15, 16, 17, 18, 19, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42)] = "No"
#Logistic Regression
rit<-glm(y~education+agree, data=WR2, family=binomial(link="logit"))
coeftest(rit)
#Confusion Matrix
probrit<-predict(rit, type="response")
predrit<-ifelse(probrit > 0.5, 1, 0)
logit<-predict(rit)
table(truth=WR2$y, prediction=predrit)%>%addmargins
WR2$logit<-logit
#Computing Accuracy
(6+12)/42
#Computing Sensitivity/Recall (TPR)
12/21
#Computing Specificity (TNR)
6/21
#Computing Precision (PPV)
12/27
#GG-Plot
library(ggplot2)
ggplot(WR2, aes(fill=sex, x=logit))+geom_density(alpha=0.3)
#ROC plot and AUC
library(plotROC)
ROCplot<-ggplot(WR2)+geom_roc(aes(d=y, m=probrit), n.cuts=0)+geom_segment(aes(x=0, xend=1, y=0, yend=1), lty=2)+scale_x_continuous(limits=c(0,1))
ROCplot
calc_auc(ROCplot)
#Repeated Random Sub-Sampling
library(tidyverse); library(lmtest); library(MASS)
WR3<-WR2%>%transmute(education=education, sex=sex, agree=agree, disagree=disagree, education_c=education_c, agree_c=agree_c, athome=athome, logit=logit, y=ifelse(sex=="Male",1,0))
jit<-glm(y~athome+education,data=WR3,family="binomial")
prob<-predict(jit,type="response")
set.seed(1234)
k=5
data1<-WR3[sample(nrow(WR3)),]
folds<-cut(seq(1:nrow(WR3)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$y
hit<-glm(y~athome+education,data=train,family="binomial")
probs<-predict(hit,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
devtools::install_github('rstudio/blogdown')
> /Users/Nyssa./Desktop/website/content/womensrole.csv
> /Users/Nyssa./Desktop/website/content/womensrole.csv
> blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::new_site(theme = "nurlansu/hugo-sustain")
install.packages("blogdown")
install.packages("blogdown")
blogdown::install_hugo()
blogdown::new_site(theme = "nurlansu/hugo-sustain")
devtools::install_github('rstudio/blogdown')
blogdown::install_hugo()
